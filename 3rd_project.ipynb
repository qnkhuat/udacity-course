{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3rd project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEBdTObn_HMp",
        "colab_type": "code",
        "outputId": "6096b2d1-53be-43a0-d728-76c2b8e7c4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        }
      },
      "source": [
        "! pip install syft"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/f4/ed95c5f6664d37a70c345f41e1bdceadc5efb2f478e2c6cd4de34f3a709a/syft-0.1.18-py3-none-any.whl (186kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 41.0MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 22.4MB/s \n",
            "\u001b[?25hCollecting lz4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.6)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.3)\n",
            "Collecting websocket-client (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.8MB/s \n",
            "\u001b[?25hCollecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 49.7MB/s \n",
            "\u001b[?25hCollecting zstd (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: tblib in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting flask-socketio (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from syft) (0.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client->syft) (1.12.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0rc1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.16.4)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/e0/a875abbb0f9d70c6e2ec2019ca9e3893377cef5deca6225ead3497000152/python_socketio-4.1.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->syft) (0.21.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask->syft) (1.1.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0rc1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.13.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/d3/de0fa7ebebd054de308e6ac397bf9e11ea42924795a38005a21ea001b114/python_engineio-3.8.1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->syft) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: websockets, lz4, websocket-client, pyyaml, tf-encrypted, zstd, python-engineio, python-socketio, flask-socketio, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 python-engineio-3.8.1 python-socketio-4.1.0 pyyaml-5.1.1 syft-0.1.18 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-7.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpR57Xp8RQsC",
        "colab_type": "code",
        "outputId": "95b96f47-05b6-4a12-ef35-f88e472032e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import torch as th\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import syft as sy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0623 15:03:34.169152 140509432104832 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0-rc1.so'\n",
            "W0623 15:03:34.185925 140509432104832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDDRI-QSRR4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(th)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsKQxUscCZHq",
        "colab_type": "text"
      },
      "source": [
        "# Trusted Aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-4XSIIb_VGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqBB-zBP_Vzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob.add_workers([alice,secure_worker])\n",
        "alice.add_workers([bob,secure_worker])\n",
        "secure_worker.add_workers([alice,bob])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fia5KTZ9_Wd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]],requires_grad = True)\n",
        "target = th.tensor([[0],[0],[1],[1.]],requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKYCNF85_XEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob_data = data[:2].send(bob)\n",
        "bob_target = target[:2].send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBnEMlHBAUn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alice_data = data[2:].send(alice)\n",
        "alice_target = target[2:].send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb00dH_mAY1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Linear(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNpbJ25mAZe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bobs_model = model.copy().send(bob)\n",
        "alices_model = model.copy().send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4KejLwpAZtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=.1)\n",
        "alices_opt = optim.SGD(params=alices_model.parameters(),lr=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeCmgbNjAaZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(10):\n",
        "    \n",
        "#     bobs_opt.zero_grad()\n",
        "#     bobs_pred = bobs_model(bob_data)\n",
        "#     bobs_loss = ((bobs_pred - bob_target)**2).sum()\n",
        "#     bobs_loss.backward()\n",
        "#     bobs_opt.step()\n",
        "\n",
        "#     alices_opt.zero_grad()\n",
        "#     alices_pred = alices_model(alice_data)\n",
        "#     alices_loss = ((alices_pred - alice_target)**2).sum()\n",
        "#     alices_loss.backward()\n",
        "#     alices_opt.step()\n",
        "\n",
        "    \n",
        "#     print(f\"Alice loss {alices_loss.get().data}\")\n",
        "#     print(f\"Bob loss {bobs_loss.get().data}\")\n",
        "#     print('-'*20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJdEnUJHAaqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alices_model.move(secure_worker)\n",
        "bobs_model.move(secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJVxkcCdAa-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with th.no_grad():\n",
        "    model.weight.set_(((alices_model.weight.data + bobs_model.weight.data)/2).get())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSCnxrgJAbCW",
        "colab_type": "text"
      },
      "source": [
        "# Additive sharing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI-zUkGbAbHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
        "\n",
        "compute_nodes = (bob, alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUve4uIJ0b-4",
        "colab_type": "code",
        "outputId": "460d101b-b290-4570-e589-1b4d5c717064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob.clear_objects()\n",
        "alice.clear_objects()\n",
        "crypto_provider.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:crypto_provider #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eDQV70bFlsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784,256)\n",
        "        self.fc2 = nn.Linear(256,64)\n",
        "        self.fc3 = nn.Linear(64,10)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.log_softmax(self.fc3(x),dim=1)\n",
        "    \n",
        "        return x\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s0n5dujD1u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_federated_data_loaders(workers):\n",
        "\n",
        "    # Define a transform to normalize the data\n",
        "    transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    # Download and load the training data\n",
        "    mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "    trainloader = th.utils.data.DataLoader(mnist_trainset, batch_size=32)\n",
        "    remote_dataset = (list(),list())\n",
        "    for i, (data, target) in enumerate(trainloader):\n",
        "        worker_index = i % len(workers)\n",
        "        data = data.send(workers[worker_index])\n",
        "        target = target.send(workers[worker_index])\n",
        "        remote_dataset[worker_index].append((data,target))\n",
        "\n",
        "    # Download and load the test data\n",
        "    mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    # Set up the testloader\n",
        "    \n",
        "    testloader = th.utils.data.DataLoader(mnist_testset, batch_size=1000, shuffle=False)\n",
        "\n",
        "\n",
        "    return remote_dataset, testloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeSbJcIED5-j",
        "colab_type": "code",
        "outputId": "8e61f904-e784-41bd-e357-ebdac299b178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "source": [
        "remote_dataset , testloader = create_federated_data_loaders(compute_nodes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:02, 3399630.63it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 48817.32it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:02, 816402.12it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 18510.46it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwdsjQHJFiKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update(data, target, model, opt, criterion):\n",
        "    model.send(data.location)\n",
        "    opt.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = criterion(pred, target)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    return model, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdBMoSvRK9Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bobs_model = Net()\n",
        "alices_model = Net()\n",
        "\n",
        "lr = 1e-2\n",
        "bobs_opt = optim.SGD(bobs_model.parameters(), lr=lr)\n",
        "alices_opt = optim.SGD(alices_model.parameters(), lr=lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uout4QxaK6za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = [bobs_model, alices_model]\n",
        "opts = [bobs_opt, alices_opt]\n",
        "params = [list(bobs_model.parameters()), \n",
        "          list(alices_model.parameters())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6Pqow9JHLyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    for e in range(epoch):\n",
        "        print(f\"{e}/{epoch}\")\n",
        "        running_loss = 0\n",
        "        for data_i in range(len(remote_dataset[0])-1):\n",
        "            # train a little bit\n",
        "            for remote_i in range(len(compute_nodes)):\n",
        "                data, target = remote_dataset[remote_i][data_i]\n",
        "                models[remote_i], loss = update(data, target, models[remote_i], \n",
        "                                          opts[remote_i], nn.NLLLoss())\n",
        "                running_loss += loss.get()\n",
        "\n",
        "\n",
        "            # aggregate params using additive sharing\n",
        "            new_params = []\n",
        "            for param_i in range(len(params[0])):\n",
        "                spdz_params = list()\n",
        "                for remote_i in range(len(compute_nodes)):\n",
        "                    # + 0 means copy\n",
        "                    remote_param = (params[remote_i][param_i] + 0).fix_precision()\n",
        "                    shared_param = remote_param.share(bob, alice, crypto_provider=crypto_provider).get()\n",
        "                    spdz_params.append(shared_param)\n",
        "                    \n",
        "                # average the params\n",
        "                new_param = (spdz_params[0] + spdz_params[1]).get().float_precision()/2\n",
        "                new_params.append(new_param)\n",
        "            \n",
        "            \n",
        "            # set the param to new trained params\n",
        "            with th.no_grad():\n",
        "                for model in params:\n",
        "                    for param in model:\n",
        "                        param *= 0\n",
        "\n",
        "                for model in models:\n",
        "                    model.get()\n",
        "\n",
        "                for remote_i in range(len(compute_nodes)):\n",
        "                    # set the new params for all worker's model\n",
        "                    for param_index in range(len(params[remote_i])):\n",
        "                        params[remote_i][param_index].set_(new_params[param_index])\n",
        "        print(f\"Loss {running_loss/len(remote_dataset[0])}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdc3YSFyL5J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    model = models[0].eval().get()\n",
        "    preds = th.tensor([])\n",
        "    for data, label in testloader:\n",
        "        out = model(data)\n",
        "        pred = th.argmax(th.exp(out),dim=1) == label\n",
        "        preds = th.cat([preds,pred.float()])\n",
        "    print(f\"Acc : {preds.float().mean()*100}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi21KXmiPWyK",
        "colab_type": "code",
        "outputId": "7b0c6886-6e67-4964-865e-13f0aafe2612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aynIwV5ZOM9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd3A4C1gOszh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}